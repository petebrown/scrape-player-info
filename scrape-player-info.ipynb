{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "MAX_THREADS = 8\n",
    "\n",
    "def construct_url(team_id, season_id):\n",
    "    url = f'https://www.soccerbase.com/teams/team.sd?team_id={team_id}&teamTabs=stats&season_id={season_id}'\n",
    "    return url\n",
    "\n",
    "def get_season_urls():\n",
    "    team_id = 2598\n",
    "    season_id = 155\n",
    "\n",
    "    url = construct_url(team_id, season_id)\n",
    "    r = requests.get(url)\n",
    "    doc = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    season_list = doc.select('#statsSeasonSelectTop option')\n",
    "    season_ids = [construct_url(team_id, season[\"value\"]) for season in season_list[1:]]\n",
    "\n",
    "    return season_ids\n",
    "\n",
    "def get_player_list(url):\n",
    "    session = requests.Session()\n",
    "    r = session.get(url)\n",
    "    doc = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    season = doc.select_one('.seasonSelector h3').text\n",
    "    player_list = doc.select('table.center tbody tr')\n",
    "\n",
    "    all_players = []\n",
    "    for player in player_list:\n",
    "        player_info = player.select_one('.first')\n",
    "\n",
    "        player_name = player_info.get_text()\n",
    "        player_name = player_name.split('(')\n",
    "        player_name = player_name[0]\n",
    "        player_name = player_name.strip()\n",
    "    \n",
    "        player_url = player_info.select_one('a')['href']\n",
    "        player_url = f\"https://www.soccerbase.com{player_url}\"\n",
    "\n",
    "        player_id = player_url.split(\"=\")[1]\n",
    "\n",
    "        all_players.append({\n",
    "            \"player_id\": player_id,\n",
    "            \"player_name\": player_name,\n",
    "            \"player_url\": player_url\n",
    "        })\n",
    "    return all_players\n",
    "\n",
    "def get_player_details(url):\n",
    "    session = requests.Session()\n",
    "    r = session.get(url)\n",
    "    doc = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    player_id = url.split(\"=\")[1]\n",
    "\n",
    "    player_position = doc.select_one((\".midfielder.bull\"))\n",
    "\n",
    "    if player_position:\n",
    "        player_position = player_position.text.strip().split(\" \")[0]\n",
    "    else:\n",
    "        player_position = \"NA\"\n",
    "\n",
    "    info_1 = pd.read_html(r.text)[1]\n",
    "    info_2 = pd.read_html(r.text)[2]\n",
    "    df = pd.concat([info_1, info_2])\n",
    "    df[\"player_id\"] = player_id\n",
    "\n",
    "    df = df.dropna().pivot(index=[\"player_id\"], columns = [0], values = [1]).reset_index()\n",
    "    df.columns = df.columns.droplevel([None]).str.lower().str.replace(\" \", \"_\")\n",
    "    player_record = df.to_dict(orient=\"records\")[0]\n",
    "    player_record[\"player_position\"] = player_position\n",
    "\n",
    "    return player_record\n",
    "\n",
    "def async_scraping(scrape_function, urls):\n",
    "    threads = min(MAX_THREADS, len(urls))\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "        results = executor.map(scrape_function, urls)\n",
    "\n",
    "    return results\n",
    "\n",
    "def add_position(player_id):\n",
    "    if player_id in [\"5682\", \"3482\", \"7940\", \"7606\", \"4316\"]:\n",
    "        position = \"Defender\"\n",
    "    elif player_id in [\"111841\"]:\n",
    "        position = \"Midfielder\"\n",
    "    elif player_id in [\"9811\"]:\n",
    "        position = \"Forward\"\n",
    "    else:\n",
    "        position = \"NA\"\n",
    "    return position\n",
    "\n",
    "def insert_manual_updates(df):\n",
    "    updates = pd.read_csv(\"./manual_updates.csv\", parse_dates=[\"player_dob\", \"date_signed\"])\n",
    "\n",
    "    df.player_id = df.player_id.astype(int)\n",
    "    df = df[~df.player_id.isin(updates.player_id)]\n",
    "    df = pd.concat([df, updates]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def main():\n",
    "    season_urls = get_season_urls()    \n",
    "\n",
    "    player_list = async_scraping(get_player_list, season_urls)\n",
    "    player_list = list(player_list)\n",
    "    player_list = [player for sublist in player_list for player in sublist]\n",
    "\n",
    "    player_urls = [player[\"player_url\"] for player in player_list]\n",
    "\n",
    "    player_info = async_scraping(get_player_details, player_urls)\n",
    "    player_info = list(player_info)\n",
    "\n",
    "    df = pd.DataFrame(player_info).drop_duplicates()\n",
    "    df[\"player_position\"] = df.apply(lambda x: add_position(x.player_id) if x.player_position == \"NA\" else x.player_position, axis=1)\n",
    "    df[\"player_dob\"] = df.age.str.split(\"Born \").str[1].str.split(\")\").str[0]\n",
    "    df[\"player_dob\"] = pd.to_datetime(df.player_dob)\n",
    "    df[\"date_signed\"] = pd.to_datetime(df.date_signed)\n",
    "    \n",
    "    df[\"height_ft\"] = df.height.str.split(\" \\(\").str[0]\n",
    "    df[\"height_cm\"] = df.height.str.split(\" \\(\").str[1].str.split(\"m\").str[0].astype(\"float\") * 100\n",
    "    df[\"weight_st\"] = df.weight.str.split(\" \\(\").str[0]\n",
    "    df[\"weight_kg\"] = df.weight.str.split(\" \\(\").str[1].str.split(\"kg\").str[0].astype(\"float\")\n",
    "\n",
    "    cols_to_keep = [\"player_id\", \"real_name\", \"player_dob\", \"player_position\", \"place_of_birth\", \"nationality\", \"height_ft\", \"height_cm\", \"weight_st\", \"weight_kg\"]\n",
    "    df = df[cols_to_keep]\n",
    "\n",
    "    df = insert_manual_updates(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/player-info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape-player-info-fc20LUjz-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eeb4e794b00aa7aa72401124ad8fe3b15f6e0429df5c23980d6b406eedb0a9c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
